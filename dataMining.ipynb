{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "This code uses __spaCy__ as model engine and the __it_core_news_lg__ as model, being this the one having the most accuracy level (0.88) in NER tasks.\n",
    "The algorithm opens the target file and pass it to the previously specified spacy model, ran locally. The function serves the purpose of injecting any given string, in our case it will be used to quickly mark all the named entities with the base tag of TEI, it will be enriched with proper metadata and attributes, implemented manually or through a data scraping function.\n",
    "\n",
    "\\#In terms of efficiency it is good practice to run first the spacy model in the second cell and then working with the following ones.<br>\n",
    "\\#The code needs spacy and the specified model to run locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'produced_data/vite-di-artiste-eccellenti.txt'\n",
    "\n",
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "    txt = f.read()\n",
    "    nlp = spacy.load('it_core_news_lg')\n",
    "    doc = nlp(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertString(string, doc, open, close, label):\n",
    "        castedString = list(string)\n",
    "        for i in doc.ents:\n",
    "            if i.label_ == label:\n",
    "                castedString[i.start_char-1] = castedString[i.start_char-1] + open\n",
    "                castedString[i.end_char-1] = castedString[i.end_char-1] + close\n",
    "\n",
    "        return ''.join(castedString)\n",
    "\n",
    "def createList(doc, label):\n",
    "    result = list()\n",
    "    for i in doc.ents:\n",
    "        if i.label_ == label:\n",
    "            result.append(i)\n",
    "    return str(set(result))\n",
    "\n",
    "# execution\n",
    "# it's slow due to a forced code solution\n",
    "# but once executed (in circa a minute you will have a full NER prediction based)\n",
    "# on every available tag in this model\n",
    "\n",
    "\n",
    "new_text = insertString(txt, nlp(txt), '<place id=''>', '</place>', 'LOC')\n",
    "new_text = insertString(new_text, nlp(new_text), '<persName id=''>', '</persName>', 'PER')\n",
    "\n",
    "# new_text = insertString(new_text, nlp(new_text), ' <org> ', ' </org> ', 'ORG')\n",
    "# new_text = insertString(new_text, nlp(new_text), ' <misc> ', ' </misc> ', 'MISC')\n",
    "\n",
    "\n",
    "# print(new_text)\n",
    "\n",
    "# with open('raw_tagged', 'w', encoding='utf-8') as f:\n",
    "#     f.write(new_text)\n",
    "\n",
    "with open('people', 'w', encoding='utf-8') as f:\n",
    "    f.write(createList(doc, \"PER\"))\n",
    "\n",
    "with open('places', 'w', encoding='utf-8') as f:\n",
    "    f.write(createList(doc, \"LOC\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2481\n"
     ]
    }
   ],
   "source": [
    "# listPers = createList(doc, \"PER\")\n",
    "# print(len(listPers))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
